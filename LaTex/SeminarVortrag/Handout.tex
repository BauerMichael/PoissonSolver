\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{ngerman}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{mathtools}

\setcounter{section}{1}
\setlength{\textwidth}{15cm}
\setlength{\unitlength}{1mm}
\setlength{\textheight}{23cm}

\title{Das Verfahren der konjugierten Gradienten}
\author{Michael Bauer}
\date{11. November 2013}

\begin{document}
\maketitle

\section*{}

%1.1 Motivation
\subsection{Motivation}
Löse ein Gleichungssystem $Ax = b$, wobei $A\in\mathbb{R}^{n}$ s.p.d., $x, b\in\mathbb{R}^{n}$ und n sehr groß.

%1.2. Definition (A-orthogonal)
\subsection{Definition (A-orthogonal)}
Sei $A$ eine symmetrische, nicht singuläre Matrix. Zwei Vektoren $x,y \in \mathbb{R}^{n}$ heißen \underline{\textbf{konjugiert}} oder \underline{\textbf{A-orthogonal}}, wenn $x^{T}Ay = 0$ ist.

%1.3.Lemma
\subsection{Lemma}
Sei $U_{k}$ ein k-dimensionaler Teilraum des $\mathbb{R}^{n} \hspace{1mm} (k \le n)$, und $p^{0}, p^{1},...,p^{k-1}$ eine $\textit{A-orthogonale Basis}$ dieses Teilraums, also $\langle p^{i}, p^{j} \rangle _{A} = 0 \hspace{2mm} f\ddot{u}r \hspace{2mm} i \ne j$. Sei $v \in \mathbb{R}^{n}$, dann gilt für $u^{k} \in U_{k}$:
\begin{equation}
\|u^{k} - v\|_{A} = \underset{u \in U_{k}}{\min} \|u - v\|_{A}
\end{equation}
genau dann, wenn $u^{k}$ die $\textit{A-orthogonale Projektion}$ von $v$ auf $U_{k} = span\{p^{0},...,p^{k-1}\}$ ist. Außerdem hat $\textbf{u}^{k}$ die Darstellung
\begin{equation}
P_{U_{k,\langle \cdot,\cdot \rangle}}(v) = \textbf{u}^{k} = \sum_{j=0}^{k-1} \frac {\langle v, p^{j} \rangle _{A}} {\langle p^{j}, p^{j} \rangle _{A}} p^{j}
\end{equation}

%1.4. Algorithmus
\subsection{Algorithmus}
Die folgenden Teilschritte definieren die Vorgehensweise zur Erzeugung der Lösung $x^{*}$ durch Näherungen $x^{1}, x^{2},...$.
\\\\$U_{1} := span\{r^{0}\}$, wobei $r^{0} = b - Ax^{0}$
\\dann gilt für $k = 1,2,3,...,$ falls $r^{k-1} = b - Ax^{k-1} \ne 0$:
\begin{description}
\item[$CG_{a}$:] Bestimme A-orthogonale Basis
\begin{equation}
p^{0},...,p^{k-1} \hspace{3mm} \textnormal{von} \hspace{3mm} U_{k}
\end{equation}
\item[$CG_{b}$:] Bestimme $x^{k} \in U_{k}$, so dass
\begin{equation}
\|x^{k} - x^{*}\|_{A} = \underset{u \in U_{k}}{\min} \|x - x^{*}\|_{A}
\end{equation}
\item[$CG_{c}$:] Erweitung des Teilraumes:
\begin{equation}
U_{k+1} := span\{p^{0},...,p^{k-1},r^{k}\} \hspace{2mm} wobei \hspace{2mm} r^{k} := b - Ax^{k}
\end{equation}
\end{description}
d.h.
\begin{align}
x^{k} = \sum_{j=0}^{k-1} \frac {\langle x^{*}, p^{j} \rangle _{A}} {\langle p^{j}, p^{j} \rangle _{A}} p^{j}
\end{align}

%1.5. Lemma
\subsection{Lemma}
Sei $x^{*}$ die Lösung von Gleichung (4) und $x^{k}$ die optimale Approximation von $x^{*}$ in $U_{k}$. Dann kann $x^{k}$ wie folgt berechnet werden:
\begin{equation}
x^{k} = x^{k-1} + \alpha_{k-1}p^{k-1}, \hspace{2mm} mit \hspace{2mm} \alpha_{k-1} := \frac {\langle r^{0}, p^{k-1} \rangle} {\langle {p^{k-1}, Ap^{k-1}} \rangle}
\end{equation}

%1.6. Lemma
\subsection{Lemma}
Um $U_{k+1}$ zu erhalten, also den Teilraum zu erweitern, muss lediglich das neue Residuum \\$r^{k} = b - Ax^{k}$ berechnet werden. Dieses erhält man durch:
\begin{equation}
r^{k} = r^{k-1} - \alpha_{k-1}Ap^{k-1}
\end{equation}
Wobei $\alpha_{k-1}$ wie in (7).

%1.7. Zusammenhang zu Krylovräumen
\subsection{Lemma (Zusammenhang zu Krylovräumen)}
Man kann $U_{k}$ auch in folgender Form schreiben:
\begin{equation}
U_{k} := span\{r^{0}, r^{1},...,r^{k-1}\} = span\{p^{0},p^{1},...,p^{k-1}\} = span\{r^{0}, Ar^{0},...,A^{k-1}r^{0}\}
\end{equation}

%1.8. Satz (Bestimmung einer A-orthogonalen Basis)
\subsection{Satz (Bestimmung einer A-orthogonalen Basis)}
Durch
\begin{equation}
p^{k-1} = r^{k-1} - \sum_{j=0}^{k-2} \frac {\langle r^{k-1}, p^{j} \rangle _{A}} {\langle p^{j}, p^{j} \rangle _{A}} p^{j}
\end{equation}
wird die A-orthogonale Basis zum Vektor $r^{k-1}$ bestimmt.

%1.9. Lemma
\subsection{Lemma}
Für jedes $\textbf{r}^{k-1}$ und $\textbf{p}^{j}$ gilt:
\begin{equation*}
\langle r^{k-1}, p^{j} \rangle _{A} = 0 \hspace{2mm} f\ddot{u}r \hspace{2mm} 0 \le j \le k-3
\end{equation*}

%1.10. Algorithmu
\subsection{Algorithmus}
Gegeben: $A \in \mathbb{R}^{n}$ s.p.d., $b \in \mathbb{R}^{n}$, Startvektor $x^{0} \in \mathbb{R}^{n}$, $\beta_{-1} := 0$. Berechne $r^{0} = b - Ax^{0}$. Für $k = 1,2,...$, falls $r^{k-1} \ne 0$:
\begin{subequations}
\begin{align}
	p^{k-1} &= r^{k-1} + \beta_{k-2}p^{k-2}, \hspace{2mm} wobei \hspace{2mm} \beta_{k-2} = \frac {\langle r^{k-1}, r^{k-1} \rangle} {\langle r^{k-2}, r^{k-2} \rangle} \hspace{2mm} mit \hspace{2mm} (k \ge 2),\\
	x^{k} &= x^{k-1} + \alpha_{k-1}p^{k-1}, \hspace{2mm} mit \hspace{2mm} \alpha_{k-1} = \frac {\langle r^{k-1}, r^{k-1} \rangle} {\langle p^{k-1}, Ap^{k-1} \rangle}\\
	r^{k} &= r^{k-1} - \alpha_{k-1}Ap^{k-1}
\end{align}
\end{subequations}

%1.15. Literatur
\subsection{Literatur:}
\begin{enumerate}
\item "'Numerik für Ingenieure und Naturwissenschaftler"', \\W.Dahmen \& A.Reusken, 2.,korrigierte Auflage, 2008, Seiten 566-572
\item "'Finite Elemente"', Braess, Seiten 177-180
\end{enumerate}

\end{document}